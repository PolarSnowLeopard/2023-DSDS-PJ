{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow as tf\n",
    "import jieba\n",
    "reviews_len_max = 261\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('token.txt','r') as f:\n",
    "    token_str = f.read()\n",
    "token = tf.keras.preprocessing.text.tokenizer_from_json(token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1dc751a3580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\r\n",
    "    #嵌入层：将已经数字化的影评转化为向量\r\n",
    "    #向量化目的：实现将词语嵌入多维矩阵，使得语义相近的词语，在空间距离上更接近\r\n",
    "    #设置输出的词向量维度为64，输入维度5000，每条文本长度与最长文本相同\r\n",
    "    tf.keras.layers.Embedding(output_dim=64,input_dim=5000,input_length=reviews_len_max),\r\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)), #RNN的双向封装器，用于对序列进行前向和后向计算\r\n",
    "    tf.keras.layers.Dense(64, activation='relu'), #隐藏层，64个神经元，激活函数为relu函数\r\n",
    "    #Dropout层以指定的丢弃概率随机丢弃上一层神经元\r\n",
    "    tf.keras.layers.Dropout(0.2), #防止过拟合：随机选择丢弃20%神经元\r\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid') #输出层\r\n",
    "])\r\n",
    "#lr指学习率，epsilon指定一个较小的数代替0，防止实现过程除以0\r\n",
    "#decay为学习率在每轮训练的衰减因子，取值范围[0,1]，0代表学习率在训练过程中保持不变\r\n",
    "#经衰减后的学习率的计算公式为lr_i = lr_start * 1.0 / (1.0 + decay*i) , i为迭代周期，lr_start是lr的初始值\r\n",
    "\r\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001,epsilon=1e-08, decay=0.0)\r\n",
    "\r\n",
    "model.compile(optimizer=adam, #指定优化器——adam\r\n",
    "              loss='binary_crossentropy', #指定损失函数——对数损失函数(针对二分类问题)\r\n",
    "              metrics=['accuracy']) #设置模型检验的方法——准确度\r\n",
    "#恢复训练的数据\r\n",
    "model.load_weights('./imdb-classify-lstm/finalmodel_weibo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    '''对每条review中的不合法字符进行替换，并进行分词转化成词表'''\n",
    "    review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    review_text = re.sub('@[\\u4e00-\\u9fa5]*|#(.)*#',\" \", review_text) #先去除用户名和话题标签\n",
    "    review_text = re.sub('[^\\u4e00-\\u9fa5]','',review_text) #再去除标点和英文\n",
    "    review_text = jieba.lcut(review_text) #分词\n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_test_sentiment(text):\n",
    "    #显示要预测的文本内容\n",
    "    #print(text)\n",
    "    #数据规范化\n",
    "    newtext=review_to_wordlist(text)\n",
    "    print(' '.join(newtext))\n",
    "    #将文本转换为数字序列\n",
    "    input_seq=token.texts_to_sequences([newtext])\n",
    "    #将序列填充或截断为固定长度的序列\n",
    "    pad_input_seq=tf.keras.preprocessing.sequence.pad_sequences(input_seq,\n",
    "                                                   padding='post',\n",
    "                                                   truncating='post',\n",
    "                                                   maxlen=reviews_len_max)\n",
    "    #使用训练好的模型进行预测\n",
    "    pred=model.predict(pad_input_seq)\n",
    "    print(pred[0][0])\n",
    "    #打印预测值\n",
    "    if pred[0][0]>0.5:\n",
    "        preValue='positive'\n",
    "    else:\n",
    "        preValue='negtive'\n",
    "    print('predict value:',preValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lenovo\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.866 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "但是 最近 我们 发现 有 同学 存在 舞弊 行为 有 同学 抄袭 了 别人 的 报告 有 同学 带 着 别人 的 报告 在 实验室 做 实验 对于 这些 行为 基础 物理 实验教学 团队 经 讨论 决定 给予 相关 同学 该 实验 分 的 处理 希望 我们 所有 同学 以此为戒 从 自身 做起 恪守 学术 道德\n",
      "0.14801186\n",
      "predict value: negtive\n"
     ]
    }
   ],
   "source": [
    "review_text='''但是，最近我们发现有同学存在舞弊行为，\n",
    "有同学抄袭了别人的报告，有同学带着别人的报告在实验室\n",
    "做实验。对于这些行为，基础物理实验教学团队经讨论决定\n",
    "给予相关同学该实验0分的处理。希望我们所有同学以此为\n",
    "戒，从自身做起，恪守学术道德。\n",
    "'''\n",
    "display_test_sentiment(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "刚 收到 北京体育大学 前 副校长 学术 带头人 胡杨 教授 去世 的 消息 他 四五年 前 就 查出 胰腺癌 还 带病 工作 几年 前 开会 坐在 他 旁边 见 他 一边 开会 一边 还 在 用 笔记本电脑 给 博士生 改 英文 文章 学术 精英 们 真的 是 太累 了 最近 年终 统计 科研 工作量 我们 学院 发了 个 论文 统计表 表中 的 位 老师 共 发表 论文 篇 和 文章 篇 只算 第一 作者 和 通讯 作者 最多 的 一年 中 就 发 了 篇 大家 想想 我们 每个 老师 的 工作量 有 多 大 竞争 压力 有 多 大 现在 还有 人 说 大学 教师 有 寒暑假 生活 很 轻松 真的 是 太 不 理解 这里 的 辛苦 了 收起 全文\n",
      "0.35257977\n",
      "predict value: negtive\n"
     ]
    }
   ],
   "source": [
    "review_text='''刚收到北京体育大学前副校长、学术带头人胡杨教授去世的消息。他四五年前就查出胰腺癌，还带病工作。几年前开会坐在他旁边，见他一边开会，一边还在用笔记本电脑给博士生改英文文章。<br><br>学术精英们真的是太累了。<br><br>最近年终统计科研工作量，我们学院发了个论文统计表。表中的81位老师，共发表SCI论文297篇和EI文章73篇（只算第一作者和通讯作者）。最多的一年中就发了17篇。大家想想，我们每个老师的工作量有多大，竞争压力有多大！<br><br>现在还有人说，大学教师有寒暑假，生活很轻松，真的是太不理解这里的辛苦了......<a href=\"javascript:void(0);\" ignore=\"ignore\" suda-data=\"key=original_blog_unfold&amp;value=click_pickup:4579973128266928:6671336585\" class=\"WB_text_opt\" action-type=\"fl_fold\">收起全文<i class=\"W_ficon ficon_arrow_up\">d</i></a>'''\n",
    "display_test_sentiment(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1条，共10条\n",
      "欧冠 超话 今夜 欧冠 小组赛 第轮 对阵 一览 拉齐奥 布鲁日 泽 尼特 多特蒙德 巴萨 尤文 切尔西 克拉 斯诺达尔 基辅 迪纳摩 费伦茨 瓦 罗斯 巴黎 伊斯坦布尔 莱比锡 曼联 雷恩 塞维利亚 收起 全文\n",
      "0.089334995\n",
      "predict value: negtive\n",
      "\n",
      "第2条，共10条\n",
      "一名 好 的 销售 必须 要 有 极 高 的 瞎聊 的 能力 销售 的 本质 其实 就是 获得 信任 你 一句 话 都 不 跟 别人 说 很 难 获得 信任 如果 要 聊聊 些 什么 客户 的 喜好 兴趣 点 差异 很大 你 最好 什么 都 能 聊 上去 能 说 个 来 因此 平常 看看 闲书 了解 一下 你 不 熟悉 的 历史 体育 地理 人文 等 在 关键 时候 都 有着 意想不到 的 作用 说到底 人生 来 寂寞 能 说些 互相 都 感兴趣 的 就是 信任 的 开始 收起 全文\n",
      "0.98020977\n",
      "predict value: positive\n",
      "\n",
      "第3条，共10条\n",
      "来 你 不要脸 我们 就 摊开 来 讨论 第一 言而无信 的 是 你 吧 说好 的 热 转前 三 最后 找前 六 企业 诚信 就 那么 一文不值 我 不 觉得 连 自己 说 的话 都 不 遵守 的 企业 有 什么 信用 可言 第二 改变 规则 不 公开 声明 信息 不 对称 的 亏 就 我们 一家 吃 了 什么 意思 啊 米子 好 欺负 呗 一条 一条 抡 出来 的 一个 一个 粉丝 的 努力 就 不配 呗 修改 规则 公开 声明 这么 简单 的 事情 都 做 不到 你 也 配 叫 企业 官博 第三 在 我家 质疑 规则 进行 沟通 的 时候 你们 给出 的 什么 意见 打扰 艺人 让 艺人 签名 补偿 粉丝 羊毛出在羊身上 这套 理念 二十一 世纪 过去 二十年 了 我 还 能 看到 着实 令人咋舌 我愿称 你们 为 不要脸 的 神 这波 是 在 鼓吹 什么 精神 够 无赖 就 能 无视 一切 努力 收起 全文\n",
      "0.015641153\n",
      "predict value: negtive\n",
      "\n",
      "第4条，共10条\n",
      "这 一年 太难 了 月 日 英国 卫生 大臣 汉考克 被 网友 发现 在 节目 中 假哭 而 遭到 批评 当天 的 节目 中当 一名 新冠 疫苗 接种 者 发表 完 感受 后 汉考克 情绪 逐渐 激动 随后 他 表示 疫情 下 的 今年 太 艰难 视频 来源 英国 卫生 大臣 节目 中 假哭 遭 质疑 这 一年 太难 澎湃 新闻 的 微博 视频\n",
      "0.9802059\n",
      "predict value: positive\n",
      "\n",
      "第5条，共10条\n",
      "送 你 一朵 小红花 花絮 今天 的 糖分 摄入 已 超标 易 烊 千玺 野花 易 烊 千玺\n",
      "0.65850234\n",
      "predict value: positive\n",
      "\n",
      "第6条，共10条\n",
      "王小波 说 这个 世上 最 伟大 的 人 是 避孕套 的 发明者 因为 他 让 一件 很 要命 的 事 变成 了 游戏 从 某种意义 上 说 他 才 是 男女平等 的 最大 最大 促进 者 有 了 这项 发明 后 女性 也 可以 自由 的 享受 乃至 你 如果 实在 气不过 不妨 从 这个 角度 来 看待 这个 问题\n",
      "0.06682563\n",
      "predict value: negtive\n",
      "\n",
      "第7条，共10条\n",
      "大盘 点评 两市 继续 走弱 多只 个股 下跌 涨停 的 和 跌停 几乎 一致 但 这样 的 弱势 行情 北向 却 逆势 净流入 多亿 北向 一般 做 多 都 是 波段 它们 入场 不 为 短线 而是 冲着 年报 行情 来 了 包括 持续 增加 的 两融 余额 也 是 一样 的 弱势 行情 最 忌讳 的 就是 追涨杀跌 因为 板块 和 个股 轮动 都 很快 这个 时候 保持 耐心 才 是 最好 的 策略 目前 判断 大盘 周四 会 继续 弱势 而 周五 则 会 出现 一波 上涨 机会 我 还是 重点 看 年报 高送 转 消费 电子 以及 顺 周期 消费 家具 家电行业 方面 新型 基建 工业 互联网 大 数据 题材 方面 利好 的 有 超清 视频 涨价 材料 等 收起 全文\n",
      "0.99437344\n",
      "predict value: positive\n",
      "\n",
      "第8条，共10条\n",
      "吃瓜 少女 张 小寒 超话 明天 系列 漫画 更新 当红 女 流量 与 男明星 的 隐秘 恋情 关键词 无间道 下载 百度搜 张 小寒 明天 提前 看 漫画\n",
      "0.11408234\n",
      "predict value: negtive\n",
      "\n",
      "第9条，共10条\n",
      "金卡纳 漂移 大片 斯巴鲁 美国 拉力 车手 驾驶 由 斯巴鲁 特制 的 漂移 车 在 市区 狂欢 该车 采用 碳纤维 车身 及 主动 空力 技术 升 水平 对置 缸 涡增 发动机 马力 牛米 视频 每 一帧 都 无比 精彩 极速 拍档 的 微博 视频\n",
      "0.1464206\n",
      "predict value: negtive\n",
      "\n",
      "第10条，共10条\n",
      "月 日 强度 榜见 图 提问 请 在 此篇后 留言 图 沪市 多方 强度 榜图 深市 多方 强度 榜图 中小 多方 强度 榜图 创业 多方 强度 榜图 沪市 多方 强度 榜图 沪市 空头 榜图 深市 空头 榜 收起 全文\n",
      "0.993889\n",
      "predict value: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt = pd.read_csv(r'F:\\python\\File\\DataAnalysis\\心理状态分析\\微博爬虫\\Weibo2_1h.csv',encoding='utf-8')\n",
    "contents = txt['content']\n",
    "#n=len(contents)\n",
    "n=10\n",
    "for i in range(8,n+8):\n",
    "    print(\"第%d条，共%d条\" % (i-7,n))\n",
    "    display_test_sentiment(contents[i*50])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}